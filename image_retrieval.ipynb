{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cb534a5",
   "metadata": {},
   "source": [
    "<h2>Indexing the document collection</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453a7cce",
   "metadata": {},
   "source": [
    "<h3>Settings & utilities</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a21f59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import xml.etree.ElementTree as ET\n",
    "import os\n",
    "import string\n",
    "import numpy as np\n",
    "import spacy #lemmatization\n",
    "import pickle #serialize object read/write files\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fc7d6b",
   "metadata": {},
   "source": [
    "<h3>Load document collection</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a68faeb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#path to the document collection\n",
    "collection_path = 'xmldocs/'\n",
    "\n",
    "def getDocumentList(path):\n",
    "    return os.listdir(path)\n",
    "    \n",
    "#generate document name list\n",
    "doc_list = getDocumentList(collection_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636f24fe",
   "metadata": {},
   "source": [
    "<h2>Processing text</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a2853e",
   "metadata": {},
   "source": [
    "<h3>Load stopwords</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0ef99c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load a stopword list NLTK\n",
    "gist_file = open(\"stopwords.txt\", \"r\")\n",
    "try:\n",
    "    content = gist_file.read()\n",
    "    stopwords = content.split(\",\")\n",
    "finally:\n",
    "    gist_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e930b89f",
   "metadata": {},
   "source": [
    "<h3>Text Processing Function</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55e7c11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Process text to meet the IR requirements\n",
    "use_lemmatization = True\n",
    "\n",
    "# Lemmatization\n",
    "# https://www.analyticsvidhya.com/blog/2019/08\n",
    "#/how-to-remove-stopwords-text-normalization-nltk-spacy-gensim-python\n",
    "#/?utm_source=blog&utm_medium=information-retrieval-using-word2vec-based-vector-space-model\n",
    "nlp = spacy.load('en_core_web_sm',disable=['ner','parser'])\n",
    "nlp.max_length=5000000\n",
    "\n",
    "def lemmatize(x):\n",
    "    return ' '.join([token.lemma_ for token in list(nlp(x)) if (token.is_stop==False)])\n",
    "    \n",
    "    \n",
    "#Returns a list of relevant terms\n",
    "def processText(text):\n",
    "    #remove punctuation and stopwords\n",
    "    #remove single punctuation characters, remove points (not separated from string), lower case all \n",
    "    if not isinstance(text, str) :\n",
    "        return []\n",
    "    #remove punctuation\n",
    "    text = text.translate(str.maketrans(string.punctuation, ' '*len(string.punctuation))).strip()\n",
    "    #remove unnecessary whitespace\n",
    "    text = text.replace(\"  \", \" \")\n",
    "    #lower the text\n",
    "    text = text.lower()\n",
    "    #lemmatize\n",
    "    if use_lemmatization:\n",
    "        text = lemmatize(text)\n",
    "    return list(filter(lambda el: el not in stopwords, text.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7d5697",
   "metadata": {},
   "source": [
    "<h2>Class for XML documents</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0344e74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class XmlFile:\n",
    "    def __init__(self, xml, xml_id, field_dict, processText):\n",
    "        self.field_dict = field_dict\n",
    "        tree = ET.parse(xml)\n",
    "        root = tree.getroot()\n",
    "        self.no_process_field_exception = ['img_dir']\n",
    "        for id in root.iter(xml_id):\n",
    "            self.id = id.text if id.text is not None else ''\n",
    "        for xml_name, field_name in field_dict.items():\n",
    "            for content in root.iter(xml_name):\n",
    "                if field_name not in self.no_process_field_exception:\n",
    "                    self.__dict__[field_name] = processText(content.text) if content.text is not None else []\n",
    "                else:\n",
    "                    self.__dict__[field_name] = content.text if content.text is not None else ''\n",
    "                \n",
    "    def __getTF__(self, processed_text):\n",
    "        #f/max_occurance of most frequent term\n",
    "        num_terms = len(processed_text)\n",
    "        tf_index = {}\n",
    "        max_term_count = 0\n",
    "        for term in processed_text:\n",
    "            if term not in tf_index: #save some time\n",
    "                term_count = processed_text.count(term)\n",
    "                if term_count > max_term_count:\n",
    "                    max_term_count = term_count\n",
    "                tf_index[term] = term_count/num_terms\n",
    "        #Normalization does not affect the results in this collection\n",
    "        #for term in tf_index.keys():\n",
    "            #tf_index[term] = tf_index[term] / max_term_count\n",
    "        return tf_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2aeac326",
   "metadata": {},
   "outputs": [],
   "source": [
    "#relevant document tags \n",
    "xml_doc_id = 'DOCID'\n",
    "xml_doc_fields = {'HEADLINE' : 'processed_head', \n",
    "                'TEXT' : 'processed_body',\n",
    "                'IMGDIR' : 'img_dir'  \n",
    "                 }\n",
    "\n",
    "class XmlDoc(XmlFile):\n",
    "    def __init__(self, xml):\n",
    "        super().__init__(xml, xml_doc_id, xml_doc_fields, processText)       \n",
    "        self.tf_head = self.__getTF__(self.processed_head)\n",
    "        self.tf_body = self.__getTF__(self.processed_body)\n",
    "        self.tf_text = self.__getTF__(self.processed_head + self.processed_body)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd3a09a",
   "metadata": {},
   "source": [
    "<h2>Document Collection</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ea6fab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocumentCollection:\n",
    "    def __init__(self, path, doc_list, \n",
    "                 model_structure_file_path = 'retrieval_model_structures/'\n",
    "                ):\n",
    "        self.docs_filename = model_structure_file_path+'document_collection.docs'\n",
    "        self.index_filename = model_structure_file_path+'document_collection.inverted_index'\n",
    "        self.global_ft_filename = model_structure_file_path+'document_collection.global_tf'\n",
    "        self.total_terms_in_collection_filename = model_structure_file_path+'document_collection.total_terms_in_collection'\n",
    "        self.idf_filename = model_structure_file_path+'document_collection.idf'\n",
    "        self.avgdl_filename = model_structure_file_path+'document_collection.avgdl'\n",
    "        self.path = path\n",
    "        self.division_factor = 10\n",
    "        #Inverted index \n",
    "            \n",
    "    def loadFromFile(self):\n",
    "        #Docs\n",
    "        self.docs = {}\n",
    "        for i in range(self.division_factor):\n",
    "            with open(self.docs_filename+'.part_'+str(i), 'rb') as dictionary_file:\n",
    "                self.docs.update(pickle.load(dictionary_file))\n",
    "        #Inverted Index\n",
    "        with open(self.index_filename, 'rb') as dictionary_file:\n",
    "            self.inverted_index = pickle.load(dictionary_file)\n",
    "        #Global TF\n",
    "        with open(self.global_ft_filename, 'rb') as dictionary_file:\n",
    "            self.global_tf = pickle.load(dictionary_file)\n",
    "        #Idf\n",
    "        with open(self.idf_filename, 'rb') as dictionary_file:\n",
    "            self.idf = pickle.load(dictionary_file)\n",
    "        #total terms in collection\n",
    "        with open(self.total_terms_in_collection_filename, 'rb') as dictionary_file:\n",
    "            self.total_terms_in_collection = pickle.load(dictionary_file)\n",
    "        #Avg Doc Length\n",
    "        with open(self.avgdl_filename, 'rb') as dictionary_file:\n",
    "            self.avgdl = pickle.load(dictionary_file)\n",
    "    \n",
    "    def computeAndDump(self, doc_list):\n",
    "        division_lenght = round(len(doc_list)/self.division_factor)\n",
    "        #Docs\n",
    "        self.docs = {}\n",
    "        for i in range(self.division_factor):\n",
    "            docs = {}\n",
    "            st = i*division_lenght\n",
    "            en = (i+1)*division_lenght\n",
    "            for d in doc_list[st:en]:\n",
    "                xml_document = XmlDoc(self.path + '/' + d)\n",
    "                docs[xml_document.id] = xml_document\n",
    "            with open(self.docs_filename+'.part_'+str(i), 'wb') as dictionary_file:\n",
    "                pickle.dump(docs, dictionary_file)\n",
    "            self.docs.update(docs)\n",
    "        \n",
    "        self.global_tf = {}\n",
    "        self.total_terms_in_collection = 0\n",
    "        self.inverted_index = {}\n",
    "        for id in self.docs.keys():\n",
    "            for term in self.docs[id].processed_head + self.docs[id].processed_body:\n",
    "                self.total_terms_in_collection += 1\n",
    "                if term not in self.global_tf:\n",
    "                    self.global_tf[term] = 1\n",
    "                else: self.global_tf[term] += 1\n",
    "                if term in self.inverted_index:\n",
    "                    self.inverted_index[term].add(id)\n",
    "                else: self.inverted_index[term] = {id}\n",
    "        for term in self.global_tf.keys():\n",
    "            self.global_tf[term] = self.global_tf[term] / self.total_terms_in_collection\n",
    "        \n",
    "        #Table of IDF\n",
    "        self.idf = {}\n",
    "        for term in self.inverted_index.keys():\n",
    "            self.idf[term] = np.log(len(self.docs) / len(self.inverted_index[term]))\n",
    "            \n",
    "        #Average document length\n",
    "        self.avgdl = np.mean([len(item.processed_head + item.processed_body) for k, item in self.docs.items()])\n",
    "        \n",
    "        with open(self.index_filename, 'wb') as dictionary_file:\n",
    "            pickle.dump(self.inverted_index, dictionary_file)\n",
    "            \n",
    "        with open(self.global_ft_filename, 'wb') as dictionary_file:\n",
    "            pickle.dump(self.global_tf, dictionary_file)\n",
    "            \n",
    "        with open(self.idf_filename, 'wb') as dictionary_file:\n",
    "            pickle.dump(self.idf, dictionary_file)\n",
    "            \n",
    "        with open(self.total_terms_in_collection_filename, 'wb') as dictionary_file:\n",
    "            pickle.dump(self.total_terms_in_collection, dictionary_file)\n",
    "            \n",
    "        with open(self.avgdl_filename, 'wb') as dictionary_file:\n",
    "            pickle.dump(self.avgdl, dictionary_file)\n",
    "        \n",
    "    \n",
    "    def getRelevance(self, document_id, term):\n",
    "        try:\n",
    "            return self.docs[document_id].tf_text[term] * self.idf[term]\n",
    "        except: \n",
    "            return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1164573a",
   "metadata": {},
   "source": [
    "<h2>Create Document Collection and Query Collection objects</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4dea647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document Collection Computed in 4.8241s\n"
     ]
    }
   ],
   "source": [
    "recompute_all = True\n",
    "#seed for random number\n",
    "seed = 1\n",
    "doc_list = getDocumentList(collection_path)\n",
    "\n",
    "#Compute or read document collection\n",
    "compute_document_collection = False or recompute_all\n",
    "\n",
    "#create a Document collection object\n",
    "document_collection = DocumentCollection(collection_path, doc_list)\n",
    "if compute_document_collection:\n",
    "    start = time.time()\n",
    "    document_collection.computeAndDump(doc_list)\n",
    "    end = time.time()\n",
    "    print('Document Collection Computed in ' + str(round(end - start, 4)) + 's')\n",
    "else:\n",
    "    start = time.time()\n",
    "    document_collection.loadFromFile()\n",
    "    end = time.time()\n",
    "    print('Document Collection Loaded in ' + str(round(end - start, 4)) + 's')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d339814",
   "metadata": {},
   "source": [
    "<h2>Classes for ranking</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3da9be9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RankResult:\n",
    "    def __init__(self, query, img_dir, relevance):\n",
    "        self.query = query\n",
    "        self.img_dir = img_dir\n",
    "        self.relevance = relevance\n",
    "        \n",
    "class RankingModel:\n",
    "    def __init__(self, document_collection):\n",
    "        self.document_collection = document_collection\n",
    "    \n",
    "    def getQueryResult(self, query, limit_result=20):\n",
    "        rank = []\n",
    "        search_space = set()\n",
    "        for term in processText(query):\n",
    "            if term in self.document_collection.inverted_index:\n",
    "                search_space = search_space.union(set(self.document_collection.inverted_index[term]))\n",
    "        for doc_id in search_space:\n",
    "            rank += [RankResult(query, self.document_collection.docs[doc_id].img_dir, self.calculateRelevance(self.document_collection.docs[doc_id], query))] \n",
    "        rank.sort(key=lambda x: x.relevance, reverse=True)\n",
    "        return rank[0:limit_result]\n",
    "    \n",
    "    def calculateRelevance(self, document, query):\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21feb291",
   "metadata": {},
   "source": [
    "<h2>Vector space model VSM</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a17c859",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorSpaceModel(RankingModel):\n",
    "    def __init__(self, document_collection):\n",
    "        super().__init__(document_collection)\n",
    "        \n",
    "    def vectorizeXmlQuery(self, query):\n",
    "        return [self.getQueryRelevance(query, t) for t in query]\n",
    "    \n",
    "    def vectorizeDocument(self, document, query):\n",
    "        return [self.getDocumentRelevance(document, t) for t in query]\n",
    "\n",
    "    #tf-idf\n",
    "    def getDocumentRelevance(self, document, term):\n",
    "        return self.document_collection.getRelevance(document.id, term)\n",
    "    \n",
    "    def getQueryRelevance(self, query, term):\n",
    "        return query.count(term)/len(query)\n",
    "\n",
    "    def dotSimilarity(self, vect1, vect2):\n",
    "        return np.dot(vect1, vect2)\n",
    "    \n",
    "    def calculateRelevance(self, document, query, similarity_function=lambda v1, v2: np.dot(v1, v2)):\n",
    "        v_query = self.vectorizeXmlQuery(query)\n",
    "        v_doc = self.vectorizeDocument(document, query)        \n",
    "        return similarity_function(v_doc, v_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f8d93b",
   "metadata": {},
   "source": [
    "<h2>Generate the VSM report for trec_eval</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7af06cbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./simple_images/Alligators/Alligators_4.jpeg'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vsm = VectorSpaceModel(document_collection)\n",
    "query = 'alligator'\n",
    "vsm.getQueryResult(query)[0].img_dir\n",
    "#document_collection.docs['1'].img_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e0d027",
   "metadata": {},
   "source": [
    "<h2>BM25 ranking</h2>\n",
    "<p>For a query $Q$ and a term $t \\in Q$, the <b>BM25</b> score for a document $D$ is: </p>\n",
    "<h1>$Relevance(D,t) = IDF(t) \\cdot \\frac{count(D, t) \\cdot (k + 1)}{count(D, t) + k \\cdot (1 - b + \\frac{b|D|}{avgdl})} $</h1>\n",
    "<p>Where $count(D, t)$ is the number of occurrences of $t$ in $D$</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff3d6afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BM25(VectorSpaceModel):\n",
    "    def __init__(self, document_collection, k = 1.2, b = .75):\n",
    "        super().__init__(document_collection)\n",
    "        self.k = k\n",
    "        self.b = b\n",
    "    \n",
    "    def getDocumentRelevance(self, document, term):\n",
    "        try:\n",
    "            idf_term = self.document_collection.idf[term]\n",
    "            #x = number of occurencies of term in document\n",
    "            x = document.tf_text[term] * len(document.processed_body+document.processed_head)\n",
    "        except:\n",
    "            return 0\n",
    "        doc_len = len(document.processed_head + document.processed_body)\n",
    "        normalizer = 1 - self.b + (self.b * doc_len / self.document_collection.avgdl)\n",
    "        return (self.k + 1) * x / (x + self.k * normalizer) * idf_term"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7310ba41",
   "metadata": {},
   "source": [
    "<h2>Generate the BM25 report for trec_eval</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9be4341a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./simple_images/Alligators/Alligators_4.jpeg'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm25 = BM25(document_collection)\n",
    "vsm.getQueryResult(query)[0].img_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689cebae",
   "metadata": {},
   "source": [
    "<h2>BM25F</h2>\n",
    "<p>In order to attribute different relevance with respect to the document fields, it is possible to use a weighted version of the $tf(D, t)$ function such that:</p>\n",
    "<h2>$tf(D, t) = \\sum_{c \\in D} w_c \\cdot tf_c(D, t)$</h2>\n",
    "<p>where:</p>\n",
    "<ul>\n",
    "    <li>$c$ is a document field</li>\n",
    "    <li>$w_c$ is the weight attributed to field c</li>\n",
    "    <li>$tf_c(D, t)$ is the term frequency for the field $c$ </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c413d22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BM25F(VectorSpaceModel):\n",
    "    def __init__(self, document_collection, k=1.2, b=.75,\n",
    "                w_head=3, w_body=1):\n",
    "        super().__init__(document_collection)\n",
    "        self.w_head = w_head\n",
    "        self.w_body = w_body\n",
    "        self.k = k\n",
    "        self.b = b\n",
    "    \n",
    "    def getDocumentRelevance(self, document, term):\n",
    "        try:\n",
    "            idf_term = self.document_collection.idf[term]\n",
    "        except:\n",
    "            return 0\n",
    "        x_head = document.tf_head[term] * len(document.processed_head) * self.w_head if term in document.tf_head else 0\n",
    "        x_body = document.tf_body[term] * len(document.processed_body) * self.w_body if term in document.tf_body else 0\n",
    "        x = x_head + x_body\n",
    "        \n",
    "        doc_len = len(document.processed_head + document.processed_body)\n",
    "        normalizer = 1 - self.b + (self.b * doc_len / self.document_collection.avgdl)\n",
    "        return (self.k + 1) * x / (x + self.k * normalizer) * idf_term\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011b575c",
   "metadata": {},
   "source": [
    "<h2>Generate the BM25F report for trec_eval</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a22a48c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./simple_images/Alligators/Alligators_4.jpeg'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm25f = BM25F(document_collection, w_head=3, w_body=1)\n",
    "bm25f.getQueryResult(query)[0].img_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece115c8",
   "metadata": {},
   "source": [
    "<h2>Unigram Language Model</h2>\n",
    "<p>A unigram language model does not consider the context and estimates each term independently. \n",
    "    As a result:\n",
    "    $P_{uni}(t_1 t_2 t_3 t_4) = P(t_1)P(t_2)P(t_3)P(t_4)$\n",
    "</p>\n",
    "\n",
    "<p>It is possible to consider a document $d$ as a generative model $M_d$ s.t. $\\sum_{t}P(t|M_d) = 1$</p>\n",
    "<p>Given a query $q$ we rank documents exploiting the likelihood of the document model to generate $q: P(q|M_d)$.</p>\n",
    "<p><b>Maximum likelihood estimate (MLE)</b> for a query $q = [t_1, \\dots, t_n]$ and a generative model $M_d$, $P(t_1, \\dots, t_n | M_d) = tf(d, t_1) \\times \\dots \\times tf(d, t_n)$</p>\n",
    "<p><b>Zero Probability Problem: </b>if a term $t_h \\in q$ is s.t. $tf(d, t_h) = 0$ hence $P(q|M_d) = 0$</p>\n",
    "<p>To overcome this problem, only query term that are present in the document will be attributed a probability, the probability of the total seen terms is normalized to $1$</p>\n",
    "<p><b>Over Estimation Problem: </b> since with MLE only terms belonging to $q \\cap d$ are estimated, if there is only one common term between document and query, i.e. $|q \\cap d| = 1$, the relevance would be $1$</p>\n",
    "<p>To overcome this second problem, it is common to attribute a mass weight to other terms in the document i.e. <b>smoothing</b>.</p>\n",
    "<p><b>Linear smoothing: </b> given a document model $M_d$ and a collection model $M_c$:</p>\n",
    "<h2>$P(t|M_d) = \\lambda \\frac{tf(d, t)}{|d|} + (1 - \\lambda) P(t|M_c)$</h2>\n",
    "<p>where $\\lambda$ is a parameter s.t. $\\lambda \\in (0, 1)$ and $P(t|M_c)$ is the term frequency of $t$ in the entire collection of documents</p>\n",
    "<p>Note: for high values of $\\lambda$ the search is more <i>conjunctive</i> i.e. favour documents containing all query terms, for low values of $\\lambda$ the search is more <i>disjunctive</i> i.e. more suitable for long queries. Tuning this parameter is collection-specific.</p>\n",
    "<p><b>Dirichlet Smoothing: </b>more effective in IR, sets <font size=\"+2\">$\\lambda = \\frac{|d|}{\\alpha + |d|}$</font> where $\\alpha$ is the background mass i.e. the number of terms not in $q \\cap d$</p>\n",
    "<p>Finally: </p>\n",
    "<h2>$P(q|d) = \\prod_{t \\in q} (\\lambda \\frac{tf(d,t)}{|d|} + (1-\\lambda) \\frac{tf(c, t)}{|c|}) = $</h2>\n",
    "<h2>$\\prod_{t \\in q} (\\frac{|d|}{\\alpha + |d|} \\frac{tf(d,t)}{|d|} + \\frac{\\alpha}{\\alpha + |d|} \\frac{tf(c, t)}{|c|}) = \\prod_{t \\in q} ( \\frac{tf(d,t)}{\\alpha + |d|} + \\frac{\\alpha}{\\alpha + |d|} \\frac{tf(c, t)}{|c|})$</h2>\n",
    "<p>Using logs to avoid underflow in computation since $log(xy) = log(x) + log(y)$: </p>\n",
    "<h2>$log(P(q|d)) = \\sum_{t \\in q} log( \\frac{tf(d,t)}{\\alpha + |d|} + \\frac{\\alpha}{\\alpha + |d|} \\frac{tf(c, t)}{|c|})$</h2>\n",
    "<p><b>Problem: </b>if a term $t$ is not present in the entire document collection, ranking of documents would be $- \\infty$, if <font size=\"+1\">$(\\frac{tf(d,t)}{\\alpha + |d|} + \\frac{\\alpha}{\\alpha + |d|} \\frac{tf(c, t)}{|c|}) = 0$</font> for a term $t$ that term will not be considered</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0502145e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnigramLanguageModel(RankingModel):\n",
    "    def __init__(self, document_collection):\n",
    "        super().__init__(document_collection)\n",
    "    \n",
    "    def calculateRelevance(self, document, query):\n",
    "        query = processText(query)\n",
    "        relevance = 0\n",
    "        d_len = len(document.processed_head + document.processed_body)\n",
    "        alpha = len([t for t in document.processed_head + document.processed_body if t not in query])\n",
    "        for t in query:\n",
    "            #must multiply * d_len because of the tf_text formulation in XmlDocument class\n",
    "            first_term = document.tf_text[t] * d_len if t in document.tf_text else 0\n",
    "            second_term = alpha * self.document_collection.global_tf[t] if t in self.document_collection.global_tf else 0#global_tf includes |c|\n",
    "            denumerator = (d_len + alpha)\n",
    "            result = (first_term + second_term) / denumerator\n",
    "            relevance += np.log(result) if result != 0 else 0 #if a term in a query is not present in entire document collection, relevance is -inf\n",
    "        return relevance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089d7bf5",
   "metadata": {},
   "source": [
    "<h2>Generate the ULM report for trec_eval</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f4cb7e61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./simple_images/Alligators/Alligators_6.jpeg'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ulm = UnigramLanguageModel(document_collection)\n",
    "ulm.getQueryResult(query)[0].img_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935050f1",
   "metadata": {},
   "source": [
    "# Python Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b17a397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__' (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://localhost:4449/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [11/Mar/2022 15:49:49] \"GET /?q=teachiing+and+learning&model=ULM HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [11/Mar/2022 15:49:49] \"GET /static/style.css HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [11/Mar/2022 15:49:49] \"GET /static/simple_images/Teaching_and_learning/Teaching%20and%20learning_6.jpeg HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [11/Mar/2022 15:49:49] \"GET /static/simple_images/Teaching_and_learning/Teaching%20and%20learning_9.jpeg HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [11/Mar/2022 15:49:49] \"GET /static/simple_images/Teaching_and_learning/Teaching%20and%20learning_4.jpeg HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [11/Mar/2022 15:49:49] \"GET /static/simple_images/Teaching_and_learning/Teaching%20and%20learning_5.jpeg HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [11/Mar/2022 15:49:49] \"GET /static/simple_images/Teaching_and_learning/Teaching%20and%20learning_7.jpeg HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [11/Mar/2022 15:49:49] \"GET /static/simple_images/Teaching_and_learning/Teaching%20and%20learning_10.jpeg HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [11/Mar/2022 15:49:49] \"GET /static/simple_images/Teaching_and_learning/Teaching%20and%20learning_1.jpeg HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [11/Mar/2022 15:49:49] \"GET /static/simple_images/Teaching_and_learning/Teaching%20and%20learning_3.jpeg HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [11/Mar/2022 15:49:49] \"GET /static/simple_images/Teaching_and_learning/Teaching%20and%20learning_8.jpeg HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [11/Mar/2022 15:49:49] \"GET /static/simple_images/Teaching_and_learning/Teaching%20and%20learning_2.jpeg HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [11/Mar/2022 15:49:59] \"GET /?q=teaching+and+learning&model=ULM HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [11/Mar/2022 15:49:59] \"GET /static/style.css HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [11/Mar/2022 15:49:59] \"GET /static/simple_images/Teaching_and_learning/Teaching%20and%20learning_4.jpeg HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [11/Mar/2022 15:49:59] \"GET /static/simple_images/Teaching_and_learning/Teaching%20and%20learning_9.jpeg HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [11/Mar/2022 15:49:59] \"GET /static/simple_images/Teaching_and_learning/Teaching%20and%20learning_6.jpeg HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [11/Mar/2022 15:49:59] \"GET /static/simple_images/Teaching_and_learning/Teaching%20and%20learning_5.jpeg HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [11/Mar/2022 15:49:59] \"GET /static/simple_images/Teaching_and_learning/Teaching%20and%20learning_7.jpeg HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [11/Mar/2022 15:49:59] \"GET /static/simple_images/Teaching_and_learning/Teaching%20and%20learning_10.jpeg HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [11/Mar/2022 15:49:59] \"GET /static/simple_images/Teaching_and_learning/Teaching%20and%20learning_1.jpeg HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [11/Mar/2022 15:49:59] \"GET /static/simple_images/Teaching_and_learning/Teaching%20and%20learning_3.jpeg HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [11/Mar/2022 15:49:59] \"GET /static/simple_images/Teaching_and_learning/Teaching%20and%20learning_8.jpeg HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [11/Mar/2022 15:49:59] \"GET /static/simple_images/Teaching_and_learning/Teaching%20and%20learning_2.jpeg HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [11/Mar/2022 15:50:03] \"GET /?q=teaching+and+learning&model=BM25 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [11/Mar/2022 15:50:03] \"GET /static/style.css HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [11/Mar/2022 15:50:04] \"GET /static/simple_images/Teaching_and_learning/Teaching%20and%20learning_8.jpeg HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [11/Mar/2022 15:50:04] \"GET /static/simple_images/Teaching_and_learning/Teaching%20and%20learning_5.jpeg HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [11/Mar/2022 15:50:04] \"GET /static/simple_images/Teaching_and_learning/Teaching%20and%20learning_1.jpeg HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [11/Mar/2022 15:50:04] \"GET /static/simple_images/Teaching_and_learning/Teaching%20and%20learning_9.jpeg HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [11/Mar/2022 15:50:04] \"GET /static/simple_images/Teaching_and_learning/Teaching%20and%20learning_4.jpeg HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [11/Mar/2022 15:50:04] \"GET /static/simple_images/Teaching_and_learning/Teaching%20and%20learning_6.jpeg HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [11/Mar/2022 15:50:04] \"GET /static/simple_images/Teaching_and_learning/Teaching%20and%20learning_7.jpeg HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [11/Mar/2022 15:50:04] \"GET /static/simple_images/Teaching_and_learning/Teaching%20and%20learning_3.jpeg HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [11/Mar/2022 15:50:04] \"GET /static/simple_images/Teaching_and_learning/Teaching%20and%20learning_10.jpeg HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [11/Mar/2022 15:50:04] \"GET /static/simple_images/Teaching_and_learning/Teaching%20and%20learning_2.jpeg HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [11/Mar/2022 15:50:08] \"GET /?q=teaching&model=BM25 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [11/Mar/2022 15:50:08] \"GET /static/style.css HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [11/Mar/2022 15:50:13] \"GET /?q=learning&model=BM25 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [11/Mar/2022 15:50:13] \"GET /static/style.css HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [11/Mar/2022 15:50:13] \"GET /static/simple_images/Teaching_and_learning/Teaching%20and%20learning_8.jpeg HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [11/Mar/2022 15:50:13] \"GET /static/simple_images/Teaching_and_learning/Teaching%20and%20learning_6.jpeg HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [11/Mar/2022 15:50:13] \"GET /static/simple_images/Teaching_and_learning/Teaching%20and%20learning_5.jpeg HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [11/Mar/2022 15:50:13] \"GET /static/simple_images/Teaching_and_learning/Teaching%20and%20learning_7.jpeg HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [11/Mar/2022 15:50:13] \"GET /static/simple_images/Teaching_and_learning/Teaching%20and%20learning_3.jpeg HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [11/Mar/2022 15:50:13] \"GET /static/simple_images/Teaching_and_learning/Teaching%20and%20learning_10.jpeg HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [11/Mar/2022 15:50:13] \"GET /static/simple_images/Teaching_and_learning/Teaching%20and%20learning_1.jpeg HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [11/Mar/2022 15:50:13] \"GET /static/simple_images/Teaching_and_learning/Teaching%20and%20learning_2.jpeg HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [11/Mar/2022 15:50:13] \"GET /static/simple_images/Teaching_and_learning/Teaching%20and%20learning_9.jpeg HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [11/Mar/2022 15:50:13] \"GET /static/simple_images/Teaching_and_learning/Teaching%20and%20learning_4.jpeg HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [11/Mar/2022 15:50:38] \"GET /?q=tattoos&model=BM25 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [11/Mar/2022 15:50:38] \"GET /static/style.css HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [11/Mar/2022 15:50:38] \"GET /static/simple_images/Tattoos/Tattoos_6.jpeg HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [11/Mar/2022 15:50:38] \"GET /static/simple_images/Tattoos/Tattoos_4.jpeg HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [11/Mar/2022 15:50:38] \"GET /static/simple_images/Tattoos/Tattoos_10.jpeg HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [11/Mar/2022 15:50:38] \"GET /static/simple_images/Tattoos/Tattoos_3.jpeg HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [11/Mar/2022 15:50:38] \"GET /static/simple_images/Tattoos/Tattoos_1.jpeg HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [11/Mar/2022 15:50:38] \"GET /static/simple_images/Tattoos/Tattoos_2.jpeg HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [11/Mar/2022 15:50:38] \"GET /static/simple_images/Tattoos/Tattoos_9.jpeg HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [11/Mar/2022 15:50:38] \"GET /static/simple_images/Tattoos/Tattoos_5.jpeg HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [11/Mar/2022 15:50:38] \"GET /static/simple_images/Tattoos/Tattoos_7.jpeg HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [11/Mar/2022 15:50:38] \"GET /static/simple_images/Tattoos/Tattoos_8.jpeg HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [11/Mar/2022 15:52:52] \"GET /?q=children&model=BM25 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [11/Mar/2022 15:52:52] \"GET /static/style.css HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [11/Mar/2022 15:52:52] \"GET /static/simple_images/Children_and_family/Children%20and%20family_4.jpeg HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [11/Mar/2022 15:52:52] \"GET /static/simple_images/Children_and_family/Children%20and%20family_6.jpeg HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [11/Mar/2022 15:52:52] \"GET /static/simple_images/Children_and_family/Children%20and%20family_7.jpeg HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [11/Mar/2022 15:52:52] \"GET /static/simple_images/Children_and_family/Children%20and%20family_3.jpeg HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [11/Mar/2022 15:52:52] \"GET /static/simple_images/Children_and_family/Children%20and%20family_8.jpeg HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [11/Mar/2022 15:52:52] \"GET /static/simple_images/Children_and_family/Children%20and%20family_9.jpeg HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [11/Mar/2022 15:52:52] \"GET /static/simple_images/Children_and_family/Children%20and%20family_2.jpeg HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [11/Mar/2022 15:52:52] \"GET /static/simple_images/Children_and_family/Children%20and%20family_5.jpeg HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [11/Mar/2022 15:52:52] \"GET /static/simple_images/Children_and_family/Children%20and%20family_10.jpeg HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [11/Mar/2022 15:52:52] \"GET /static/simple_images/Children_and_family/Children%20and%20family_1.jpeg HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [11/Mar/2022 15:52:56] \"GET /?q=family&model=BM25 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [11/Mar/2022 15:52:56] \"GET /static/style.css HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [11/Mar/2022 15:52:56] \"GET /static/simple_images/Children_and_family/Children%20and%20family_6.jpeg HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [11/Mar/2022 15:52:56] \"GET /static/simple_images/Children_and_family/Children%20and%20family_7.jpeg HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [11/Mar/2022 15:52:56] \"GET /static/simple_images/Children_and_family/Children%20and%20family_3.jpeg HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [11/Mar/2022 15:52:56] \"GET /static/simple_images/Children_and_family/Children%20and%20family_8.jpeg HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [11/Mar/2022 15:52:56] \"GET /static/simple_images/Children_and_family/Children%20and%20family_2.jpeg HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [11/Mar/2022 15:52:56] \"GET /static/simple_images/Children_and_family/Children%20and%20family_9.jpeg HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [11/Mar/2022 15:52:56] \"GET /static/simple_images/Children_and_family/Children%20and%20family_5.jpeg HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [11/Mar/2022 15:52:56] \"GET /static/simple_images/Children_and_family/Children%20and%20family_10.jpeg HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [11/Mar/2022 15:52:56] \"GET /static/simple_images/Children_and_family/Children%20and%20family_4.jpeg HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [11/Mar/2022 15:52:56] \"GET /static/simple_images/Children_and_family/Children%20and%20family_1.jpeg HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [11/Mar/2022 15:53:19] \"GET /?q=Red+Cross&model=BM25 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [11/Mar/2022 15:53:20] \"GET /static/style.css HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [11/Mar/2022 15:53:20] \"GET /static/simple_images/Red_Cross/Red%20Cross_10.jpeg HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [11/Mar/2022 15:53:20] \"GET /static/simple_images/Robotics/Robotics_4.jpeg HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [11/Mar/2022 15:53:20] \"GET /static/simple_images/Nutrition/Nutrition_1.jpeg HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [11/Mar/2022 15:53:20] \"GET /static/simple_images/Red_Cross/Red%20Cross_7.jpeg HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [11/Mar/2022 15:53:20] \"GET /static/simple_images/Red_Cross/Red%20Cross_3.jpeg HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [11/Mar/2022 15:53:20] \"GET /static/simple_images/Shovels/Shovels_9.jpeg HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [11/Mar/2022 15:53:20] \"GET /static/simple_images/Red_Cross/Red%20Cross_6.jpeg HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [11/Mar/2022 15:53:20] \"GET /static/simple_images/Red_Cross/Red%20Cross_8.jpeg HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [11/Mar/2022 15:53:20] \"GET /static/simple_images/Red_Cross/Red%20Cross_4.jpeg HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [11/Mar/2022 15:53:20] \"GET /static/simple_images/Red_Cross/Red%20Cross_1.jpeg HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, render_template, request\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/')\n",
    "def home():\n",
    "    model = request.args.get('model') if request.args.get('model') is not None else 'VSM'\n",
    "    q = request.args.get('q') if request.args.get('q') is not None else ''\n",
    "    limit = int(request.args.get('limit')) if request.args.get('limit') is not None else 10\n",
    "\n",
    "    vsm_c, bm25_c, ulm_c = '', '', ''\n",
    "    \n",
    "    if model == 'VSM':\n",
    "        vsm_c = 'checked'\n",
    "        q_res = [r.img_dir[1:] for r in vsm.getQueryResult(q, limit)]\n",
    "    \n",
    "    if model == 'BM25':\n",
    "        bm25_c = 'checked'\n",
    "        q_res = [r.img_dir[1:] for r in bm25.getQueryResult(q, limit)]\n",
    "    \n",
    "    if model == 'ULM':\n",
    "        ulm_c = 'checked'\n",
    "        q_res = [r.img_dir[1:] for r in ulm.getQueryResult(q, limit)]\n",
    "    \n",
    "    return f\"\"\"\n",
    "    \n",
    "        <!DOCTYPE html>\n",
    "        <html>\n",
    "        <head>\n",
    "            <title>Image Retrieval WebApp</title>\n",
    "            <link href=\"static/style.css\" rel=\"stylesheet\" />\n",
    "            <link rel=\"preconnect\" href=\"https://fonts.googleapis.com\">\n",
    "            <link rel=\"preconnect\" href=\"https://fonts.gstatic.com\" crossorigin>\n",
    "            <link href=\"https://fonts.googleapis.com/css2?family=Montserrat:wght@300&display=swap\" rel=\"stylesheet\"> \n",
    "        </head>\n",
    "        <body>\n",
    "            <h2>Image Search Engine</h2>\n",
    "            <form id=\"search-commands\">\n",
    "            <input placeholder=\"Type your search terms\" type=\"text\" name=\"q\" value=\"{q}\" />\n",
    "            <input type=\"submit\" value=\"search images\" /> <br><br>\n",
    "            <b>Select engine</b>:\n",
    "            <span class=\"eng\">\n",
    "                <input type=\"radio\" name=\"model\"  value=\"VSM\" {vsm_c}> \n",
    "                <label for=\"VSM\">VSM <i>tf-idf</i></label>\n",
    "            </span>\n",
    "            <span class=\"eng\">\n",
    "                <input type=\"radio\" name=\"model\" value=\"BM25\" {bm25_c}>\n",
    "                <label for=\"BM25\">BM25</label>\n",
    "            </span>\n",
    "            <span class=\"eng\">\n",
    "                <input type=\"radio\" name=\"model\"  value=\"ULM\" {ulm_c}> \n",
    "                <label for=\"ULM\">ULM</label>\n",
    "            </span>\n",
    "            </form>\n",
    "            <i>Don't know what to search?</i> <span id=\"myBtn\">List of topics</span>\n",
    "            <div id=\"img-container\">\n",
    "            {rend_imgs(q_res)}\n",
    "            </div>\n",
    "            <div id=\"myModal\" class=\"modal\">\n",
    "\n",
    "              <!-- Modal content -->\n",
    "              <div class=\"modal-content\">\n",
    "                <span class=\"close\">&times;</span>\n",
    "                <p>{topics_text()}</p>\n",
    "              </div>\n",
    "\n",
    "            </div>\n",
    "        </body>\n",
    "        <script>\n",
    "        var modal = document.getElementById(\"myModal\");\n",
    "        var btn = document.getElementById(\"myBtn\");\n",
    "        var span = document.getElementsByClassName(\"close\")[0];\n",
    "        btn.onclick = function() {{\n",
    "          modal.style.display = \"block\";\n",
    "        }}\n",
    "\n",
    "        // When the user clicks on <span> (x), close the modal\n",
    "        span.onclick = function() {{\n",
    "          modal.style.display = \"none\";\n",
    "        }}\n",
    "\n",
    "        // When the user clicks anywhere outside of the modal, close it\n",
    "        window.onclick = function(event) {{\n",
    "          if (event.target == modal) {{\n",
    "            modal.style.display = \"none\";\n",
    "          }}\n",
    "        }}\n",
    "        </script>\n",
    "        </html>\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "def topics_text():\n",
    "    #Read topics from file (100 topics)\n",
    "    topics = open(\"topics.txt\", \"r\")\n",
    "    content_list = topics.readlines()\n",
    "    topics.close()\n",
    "    #Prepare topics for downloader\n",
    "    content_list = ['<span class=\"topic-entry\">' + el.strip() + '</span>' for el in content_list]\n",
    "    topics_search_str = ' '.join(content_list)\n",
    "    return topics_search_str\n",
    "\n",
    "def rend_imgs(img_list):\n",
    "    if len(img_list) == 0:\n",
    "        return 'No results found..'\n",
    "    r = ''\n",
    "    for el in img_list:\n",
    "        r += '<img height=\"150\" src=\"static' + el + '\" alt=\"User Image\">'\n",
    "    return r\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Run the app server on localhost:4449\n",
    "    app.run('localhost', 4449)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072d5866",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
